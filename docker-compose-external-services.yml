services:
  zookeeper:
    image: quay.io/debezium/zookeeper:3.2
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - devohh-network
    volumes:
      - zookeeper-data:/var/lib/zookeeper

  kafka:
    image: quay.io/debezium/kafka:3.2
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://kafka:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # ✅ Increase message & batch size limits
      KAFKA_MESSAGE_MAX_BYTES: 50000000               # 50 MB per message
      KAFKA_REPLICA_FETCH_MAX_BYTES: 50000000         # 50 MB per fetch
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 50000000         # 50 MB per fetch
      KAFKA_MAX_REQUEST_SIZE: 50000000                # 50 MB per request

      # ✅ Improve throughput for high-volume CDC events
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600       # 100 MB max socket request

      # ✅ Ensure internal topics can handle larger messages
      KAFKA_LOG_SEGMENT_BYTES: 1073741824             # 1 GB per segment
      KAFKA_LOG_RETENTION_HOURS: 168                  # 7 days retention
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000   # 5 minutes check
    networks:
      - devohh-network
    volumes:
      - kafka-data:/var/lib/kafka/data

  connect:
    image: quay.io/debezium/connect:3.2
    container_name: connect
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    networks:
      - devohh-network
    volumes:
      - connect-data:/kafka/connect

  postgres:
    image: postgres:15
    container_name: postgres
    ports:
      - "5432:5432"
    command: postgres -c wal_level=logical -c max_wal_senders=10 -c max_replication_slots=10
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: contests_db
    networks:
      - devohh-network
    volumes:
      - db-data:/var/lib/postgresql/data

  # rabbitmq:
  #   image: rabbitmq:3-management
  #   container_name: rabbitmq
  #   ports:
  #     - "5672:5672"
  #     - "15672:15672"
  #   environment:
  #     RABBITMQ_DEFAULT_USER: guest
  #     RABBITMQ_DEFAULT_PASS: guest
  #   volumes:
  #     - rabbitmq-data:/var/lib/rabbitmq
  #   networks:
  #     - devohh-network

volumes:
  db-data:
  # rabbitmq-data:
  zookeeper-data:
  kafka-data:
  connect-data:

networks:
  devohh-network:
    external: true